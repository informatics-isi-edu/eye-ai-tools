{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/informatics-isi-edu/eye-ai-tools/blob/main/notebooks/Eye_ai_Image_Cropping_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBNfD8vlKgev"
      },
      "outputs": [],
      "source": [
        "# Prerequisites\n",
        "!pip install git+https://github.com/fair-research/bdbag\n",
        "!pip install git+https://github.com/informatics-isi-edu/deriva-py\n",
        "!pip install 'git+https://github.com/informatics-isi-edu/eye-ai-tools' --upgrade --force\n",
        "!pip install 'git+https://github.com/informatics-isi-edu/deriva-ml' --upgrade --force\n",
        "!pip install git+https://github.com/informatics-isi-edu/eye-ai-ml\n",
        "!pip install pydantic --upgrade --force\n",
        "\n",
        "import json\n",
        "import os\n",
        "from eye_ai import EyeAI\n",
        "import pandas as pd\n",
        "from pathlib import Path, PurePath\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw-bW4bORlqQ"
      },
      "outputs": [],
      "source": [
        "# @title login to DERIVA via Globus Auth\n",
        "\n",
        "DEBUG_MODE = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "catalog_id = \"eye-ai\" #@param\n",
        "DEFAULT_SERVER = 'dev.eye-ai.org' if DEBUG_MODE else 'www.eye-ai.org'\n",
        "\n",
        "!deriva-globus-auth-utils login --no-browser --host {DEFAULT_SERVER}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EA = EyeAI(hostname = DEFAULT_SERVER, catalog_id = catalog_id )"
      ],
      "metadata": {
        "id": "A1Cg1lLQiSk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCIfOvbUXTGB"
      },
      "outputs": [],
      "source": [
        "# @title Initiate an Execution\n",
        "configuration_records = EA.execution_init(configuration_rid=\"2-5NZC\")\n",
        "configuration_records\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUuTRgyg7Ys1"
      },
      "outputs": [],
      "source": [
        "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
        "bag_path1 = configuration_records['bag_paths'][0]\n",
        "Dataset_Path = PurePath(bag_path1, 'data/Image.csv')\n",
        "Dataset = pd.read_csv(Dataset_Path)\n",
        "\n",
        "Dataset_Field_2 = Dataset[Dataset['Image_Angle_Vocab'] == \"2SK6\"]\n",
        "\n",
        "# For sanity check, compare the filtered data length by just taking the Filename column and filtering it with the same condition where it has Field 2 in it as a substring.\n",
        "\n",
        "print(len(Dataset_Field_2))\n",
        "print(len(Dataset[Dataset['Filename'].str.contains(\"Field 2\")]))\n",
        "\n",
        "file2_csv_path = PurePath(bag_path1, 'Field_2.csv')\n",
        "Dataset_Field_2.to_csv(file2_csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Execute ML algorithm (Cropping)\n",
        "from eye_ai_ml.glaucoma.optic_disk_crop import preprocess_and_crop\n",
        "cm = EA.start_execution(execution_rid=configuration_records['execution'])\n",
        "with cm as exec:\n",
        "  preprocess_and_crop(\n",
        "      bag_path1+\"/data/assets/Image/\",\n",
        "      file2_csv_path,\n",
        "      './output/output.csv',\n",
        "      'template.jpg',\n",
        "      './output/',\n",
        "      './'+configuration_records['model_paths'][0],\n",
        "      configuration_records['execution'],\n",
        "      configuration_records['annotation_tag_rid'],\n",
        "      EA.configuration.annotation_tag.name\n",
        "      )"
      ],
      "metadata": {
        "id": "YIJj6Uj73sOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT2etwRNVmjo"
      },
      "outputs": [],
      "source": [
        "# @title ML result analysis\n",
        "import numpy as np\n",
        "output_csv_path = \"./output/output.csv\"\n",
        "cropped_info = pd.read_csv(output_csv_path)[[\"Image RID\", \"Worked Image Cropping Function\"]]\n",
        "\n",
        "cropped_info['Cropped'] = np.where(cropped_info['Worked Image Cropping Function'] == 'Raw Cropped to Eye', 'False', 'True')\n",
        "cropped_info = cropped_info[[\"Image RID\", \"Cropped\"]]\n",
        "cropped_info.rename(columns={'Image RID': 'RID'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PodDp0IvObZP"
      },
      "outputs": [],
      "source": [
        "# @title Upload ML results\n",
        "# upload cropping bounding box\n",
        "EA.upload_assets(f'./output/{configuration_records[\"execution\"]}')\n",
        "\n",
        "# upload cropping metadata\n",
        "EA.update_image_table(cropped_info)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}